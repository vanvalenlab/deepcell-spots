{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepcell.datasets import SpotNet\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "from deepcell_spots import dotnet_losses\n",
    "from deepcell_spots import image_generators\n",
    "from deepcell_spots.utils.postprocessing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_net = SpotNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = spot_net.load_data(split='train')\n",
    "train_dict = {'X': train_X, 'y': train_y}\n",
    "\n",
    "val_X, val_y = spot_net.load_data(split='val')\n",
    "val_dict = {'X': val_X, 'y': val_y}\n",
    "\n",
    "test_X, test_y = spot_net.load_data(split='test')\n",
    "test_dict = {'X': test_X, 'y': test_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set size: {}'.format(train_dict['X'].shape))\n",
    "print('Validation set size: {}'.format(val_dict['X'].shape))\n",
    "print('Test set size: {}'.format(test_dict['X'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize to check that it loaded correctly\n",
    "ind=0\n",
    "plt.imshow(train_dict['X'][ind,...,0])\n",
    "plt.scatter(train_dict['y'][ind][:,1], train_dict['y'][ind][:,0], edgecolors='r', facecolors='None', s=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up required filepaths\n",
    "\n",
    "modeldir = './models'\n",
    "logdir = './logs'\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in (modeldir, logdir):\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "print('model dir: ', modeldir)\n",
    "print('log dir: ', logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "conv_model_name = 'example_conv_dots_model'\n",
    "\n",
    "n_epoch = 10  # Number of training epochs\n",
    "norm_method = None  # data normalization - options are: 'std','max', None, 'whole_image'\n",
    "receptive_field = 13  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# FC training settings\n",
    "n_skips = 3  # number of skip-connections (only for FC training)\n",
    "batch_size = 1  # FC training uses 1 image per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell_spots.dotnet import dot_net_2D\n",
    "\n",
    "dots_model = dot_net_2D(receptive_field=receptive_field,\n",
    "               input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "               inputs=None,\n",
    "               n_skips=n_skips,\n",
    "               norm_method=norm_method,\n",
    "               padding_mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=3.0\n",
    "gamma=0.5\n",
    "focal = False\n",
    "\n",
    "losses = dotnet_losses.DotNetLosses(\n",
    "    sigma=sigma, gamma=gamma, focal=focal)\n",
    "\n",
    "loss = {\n",
    "    'offset_regression': losses.regression_loss,\n",
    "    'classification': losses.classification_loss\n",
    "}\n",
    "\n",
    "regression_weight = 1\n",
    "classification_weight = 5\n",
    "total_weight = regression_weight + classification_weight\n",
    "    \n",
    "loss_weights = {\n",
    "    \"offset_regression\": regression_weight / total_weight,\n",
    "    \"classification\": classification_weight / total_weight\n",
    "}\n",
    "dots_model.compile(loss=loss, loss_weights=loss_weights,\n",
    "              optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_range=0\n",
    "flip=True\n",
    "shear=0\n",
    "zoom_range=0\n",
    "fill_mode='nearest'\n",
    "cval=0.\n",
    "seed=0\n",
    "\n",
    "datagen = image_generators.ImageFullyConvDotDataGenerator(\n",
    "    rotation_range=rotation_range,\n",
    "    shear_range=shear,\n",
    "    zoom_range=zoom_range,\n",
    "    horizontal_flip=flip,\n",
    "    vertical_flip=flip,\n",
    "    fill_mode=fill_mode,\n",
    "    cval=cval)\n",
    "\n",
    "# DataGenerator object for validation data - generates data with no augmentation\n",
    "datagen_val = image_generators.ImageFullyConvDotDataGenerator(\n",
    "    rotation_range=0,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=0,\n",
    "    vertical_flip=0)\n",
    "\n",
    "train_data = datagen.flow(\n",
    "    train_dict,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_data = datagen_val.flow(\n",
    "    val_dict,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_gpus=1\n",
    "loss_history = dots_model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.y.shape[0] // batch_size,\n",
    "    epochs=n_epoch,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.y.shape[0] // batch_size,\n",
    "    callbacks=[\n",
    "        callbacks.LearningRateScheduler(lr_sched),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            modeldir, monitor='val_loss', verbose=1,\n",
    "            save_best_only=True, save_weights_only=num_gpus >= 2),\n",
    "        callbacks.TensorBoard(log_dir=os.path.join(logdir, conv_model_name))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = dots_model.predict(test_dict['X'])\n",
    "print('Test image result shape:', y_pred_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "# plots results with restrictive decision\n",
    "fig,ax=plt.subplots(1, 2, figsize=(10,5))\n",
    "ax[0].imshow(test_dict['X'][ind,...,0], cmap='gray')\n",
    "ax[0].set_title('Raw image')\n",
    "\n",
    "# mark above threshold pixels (opaque plot over original)\n",
    "threshold = 0.95\n",
    "y_pred_test_dict = {}\n",
    "y_pred_test_dict['classification'] = y_pred_test[1]\n",
    "y_pred_test_dict['offset_regression'] = y_pred_test[0]\n",
    "points_list = y_annotations_to_point_list_max(y_pred_test_dict, threshold, min_distance=1)\n",
    "# plot ground truth centers, and predictions\n",
    "ax[1].imshow(y_pred_test[1][ind,:,:,1], vmax=vmax, cmap='gray')\n",
    "ax[1].scatter(points_list[ind][:,1], points_list[ind][:,0], edgecolors='r',\n",
    "              facecolors='None', s=200, label='Predicted')\n",
    "ax[1].plot(test_dict['y'][ind][:,1], test_dict['y'][ind][:,0], 'xb', label='GT')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Classification prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
